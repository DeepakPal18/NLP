{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3307b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c45596",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020d4f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run',\n",
       " 'runs',\n",
       " 'running',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'gone',\n",
       " 'going',\n",
       " 'easy',\n",
       " 'easily',\n",
       " 'history',\n",
       " 'historical',\n",
       " 'historian']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['run','runs','running','go','goes','gone','going','easy','easily',\n",
    "         'history','historical','historian']\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aba7c5",
   "metadata": {},
   "source": [
    "### Stemming- May or may not give meaningful words(shorten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefd4743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run--->run\n",
      "runs--->run\n",
      "running--->run\n",
      "go--->go\n",
      "goes--->goe\n",
      "gone--->gone\n",
      "going--->go\n",
      "easy--->easi\n",
      "easily--->easili\n",
      "history--->histori\n",
      "historical--->histor\n",
      "historian--->historian\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '--->' +p_stem.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f151c38",
   "metadata": {},
   "source": [
    "#### snowballstemmer- (another way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a083282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stem = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "927cfd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run--->run\n",
      "runs--->run\n",
      "running--->run\n",
      "go--->go\n",
      "goes--->goe\n",
      "gone--->gone\n",
      "going--->go\n",
      "easy--->easi\n",
      "easily--->easili\n",
      "history--->histori\n",
      "historical--->histor\n",
      "historian--->historian\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '--->' +s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1818e",
   "metadata": {},
   "source": [
    "### Lemmatization - Meaningful words(shorten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d39fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b6f8eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run--->run\n",
      "runs--->run\n",
      "running--->running\n",
      "go--->go\n",
      "goes--->go\n",
      "gone--->gone\n",
      "going--->going\n",
      "easy--->easy\n",
      "easily--->easily\n",
      "history--->history\n",
      "historical--->historical\n",
      "historian--->historian\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '--->' +lemm.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c3caaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polar lights (aurora polaris) are a natural phenomenon found in both the northern and southern hemispheres that can be truly awe inspiring. Northern lights are also called by their scientific name, aurora borealis, and southern lights are called aurora australis.Sten Odenwald, author of The 23rd Cycle: learning to live with a stormy star (New York, Columbia University Press, c2001), provides insight into how northern lights are generated:The origin of the aurora begins on the surface of the sun when solar activity ejects a cloud of gas. Scientists call this a coronal mass ejection (CME). If one of these reaches earth, taking about 2 to 3 days, it collides with the Earth’s magnetic field. This field is invisible, and if you could see its shape, it would make Earth look like a comet with a long magnetic ‘tail’ stretching a million miles behind Earth in the opposite direction of the sun.When a coronal mass ejection collides with the magnetic field, it causes complex changes to happen to the magnetic tail region. These changes generate currents of charged particles, which then flow along lines of magnetic force into the Polar Regions. These particles are boosted in energy in Earth’s upper atmosphere, and when they collide with oxygen and nitrogen atoms, they produce dazzling auroral light.Odenwald further tells us “Aurora are beautiful, but the invisible flows of particles and magnetism that go on at the same time can damage our electrical power grid and satellites operating in space. This is why scientists are so keen to understand the physics of aurora and solar storms, so we can predict when our technologies may be affected.”'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = \"Polar lights (aurora polaris) are a natural phenomenon found in both the northern and southern hemispheres that can be truly awe inspiring. Northern lights are also called by their scientific name, aurora borealis, and southern lights are called aurora australis.Sten Odenwald, author of The 23rd Cycle: learning to live with a stormy star (New York, Columbia University Press, c2001), provides insight into how northern lights are generated:The origin of the aurora begins on the surface of the sun when solar activity ejects a cloud of gas. Scientists call this a coronal mass ejection (CME). If one of these reaches earth, taking about 2 to 3 days, it collides with the Earth’s magnetic field. This field is invisible, and if you could see its shape, it would make Earth look like a comet with a long magnetic ‘tail’ stretching a million miles behind Earth in the opposite direction of the sun.When a coronal mass ejection collides with the magnetic field, it causes complex changes to happen to the magnetic tail region. These changes generate currents of charged particles, which then flow along lines of magnetic force into the Polar Regions. These particles are boosted in energy in Earth’s upper atmosphere, and when they collide with oxygen and nitrogen atoms, they produce dazzling auroral light.Odenwald further tells us “Aurora are beautiful, but the invisible flows of particles and magnetism that go on at the same time can damage our electrical power grid and satellites operating in space. This is why scientists are so keen to understand the physics of aurora and solar storms, so we can predict when our technologies may be affected.”\"\n",
    "para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d453c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming - \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b465ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sen = nltk.sent_tokenize(para)\n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ad2270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Polar lights (aurora polaris) are a natural phenomenon found in both the northern and southern hemispheres that can be truly awe inspiring.',\n",
       " 'Northern lights are also called by their scientific name, aurora borealis, and southern lights are called aurora australis.Sten Odenwald, author of The 23rd Cycle: learning to live with a stormy star (New York, Columbia University Press, c2001), provides insight into how northern lights are generated:The origin of the aurora begins on the surface of the sun when solar activity ejects a cloud of gas.',\n",
       " 'Scientists call this a coronal mass ejection (CME).',\n",
       " 'If one of these reaches earth, taking about 2 to 3 days, it collides with the Earth’s magnetic field.',\n",
       " 'This field is invisible, and if you could see its shape, it would make Earth look like a comet with a long magnetic ‘tail’ stretching a million miles behind Earth in the opposite direction of the sun.When a coronal mass ejection collides with the magnetic field, it causes complex changes to happen to the magnetic tail region.',\n",
       " 'These changes generate currents of charged particles, which then flow along lines of magnetic force into the Polar Regions.',\n",
       " 'These particles are boosted in energy in Earth’s upper atmosphere, and when they collide with oxygen and nitrogen atoms, they produce dazzling auroral light.Odenwald further tells us “Aurora are beautiful, but the invisible flows of particles and magnetism that go on at the same time can damage our electrical power grid and satellites operating in space.',\n",
       " 'This is why scientists are so keen to understand the physics of aurora and solar storms, so we can predict when our technologies may be affected.”']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f775f20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['polar light ( aurora polari ) natur phenomenon found northern southern hemisph truli awe inspir .',\n",
       " 'northern light also call scientif name , aurora boreali , southern light call aurora australis.sten odenwald , author 23rd cycl : learn live stormi star ( new york , columbia univ press , c2001 ) , provid insight northern light gener : origin aurora begin surfac sun solar activ eject cloud ga .',\n",
       " 'scientist call coron mass eject ( cme ) .',\n",
       " 'one reach earth , take 2 3 day , collid earth ’ magnet field .',\n",
       " 'thi field invi , could see shape , would make earth look like comet long magnet ‘ tail ’ stretch million mile behind earth opposit direct sun.when coron mass eject collid magnet field , cau complex chang happen magnet tail region .',\n",
       " 'chang gener current charg particl , flow along line magnet forc polar region .',\n",
       " 'particl boost energi earth ’ upper atmosph , collid oxygen nitrogen atom , produc dazzl auror light.odenwald tell us “ aurora beauti , invi flow particl magnet go time damag electr power grid satellit oper space .',\n",
       " 'thi scientist keen understand physic aurora solar storm , predict technolog may affect . ”']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(p_sen)):\n",
    "    words = nltk.word_tokenize(p_sen[i]) # word tokenize\n",
    "    words = [stem.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    p_sen[i] = \" \".join(words)\n",
    "p_sen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae833803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization -\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "p_sen = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e122ef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Polar light ( aurora polaris ) natural phenomenon found northern southern hemisphere truly awe inspiring .',\n",
       " 'Northern light also called scientific name , aurora borealis , southern light called aurora australis.Sten Odenwald , author The 23rd Cycle : learning live stormy star ( New York , Columbia University Press , c2001 ) , provides insight northern light generated : The origin aurora begin surface sun solar activity ejects cloud gas .',\n",
       " 'Scientists call coronal mass ejection ( CME ) .',\n",
       " 'If one reach earth , taking 2 3 day , collides Earth ’ magnetic field .',\n",
       " 'This field invisible , could see shape , would make Earth look like comet long magnetic ‘ tail ’ stretching million mile behind Earth opposite direction sun.When coronal mass ejection collides magnetic field , cause complex change happen magnetic tail region .',\n",
       " 'These change generate current charged particle , flow along line magnetic force Polar Regions .',\n",
       " 'These particle boosted energy Earth ’ upper atmosphere , collide oxygen nitrogen atom , produce dazzling auroral light.Odenwald tell u “ Aurora beautiful , invisible flow particle magnetism go time damage electrical power grid satellite operating space .',\n",
       " 'This scientist keen understand physic aurora solar storm , predict technology may affected . ”']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(p_sen)):\n",
    "    words = nltk.word_tokenize(p_sen[i]) # word tokenize\n",
    "#     words = re.sub('[^a-zA-Z0-9]','',p_sen[i])\n",
    "    words = [lemm.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    p_sen[i] = \" \".join(words)\n",
    "p_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd56d7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thisisatest'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^0-9a-zA-Z]\",\"\",\"this is a test!!\") # '\\W' is the same as [^A-Za-z0-9_] plus accented chars from your locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19f337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b3c6634",
   "metadata": {},
   "source": [
    "### spacy(package)-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10af5dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.1-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 12.2/12.2 MB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\anaconda\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\anaconda\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in e:\\anaconda\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from spacy) (22.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.9-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 18.8 MB/s eta 0:00:00\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.6-cp39-cp39-win_amd64.whl (482 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in e:\\anaconda\\lib\\site-packages (from spacy) (1.10.5)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in e:\\anaconda\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in e:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in e:\\anaconda\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 spacy-3.5.1 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.9 typer-0.7.0 wasabi-1.1.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72ca94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9d82f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 9.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in e:\\anaconda\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\anaconda\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in e:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in e:\\anaconda\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\anaconda\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in e:\\anaconda\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36c11bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4ef0be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87e02882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
      "Verbs: ['start', 'work', 'drive', 'take', 'tell', 'shake', 'turn', 'talk', 'say']\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "974b8cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun PERSON\n",
      "Recode ORG\n",
      "earlier this week DATE\n"
     ]
    }
   ],
   "source": [
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540b935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664135f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebea50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b5da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
